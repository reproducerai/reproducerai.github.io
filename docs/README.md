### Purpose
- Test how different AI architectures, learning strategies, and datasets affect model performance in a easy-to-understand way.
- Use synthetic datasets in a controlled environment to isolate and understand the impact of each change.
- Share findings and insights here.

---

### Goal
AI papers adopt certain hyperparameters, architectural choices, or learning strategies without really explaining why they work. AI development is still trial and error. I want to explore the fundamentals of AI, so we can make model design and training more deliberate, predictable, and less based on intuition or guesswork.

---

### Connect
- [LinkedIn](https://www.linkedin.com/in/minhaj-uddin-ansari-040573160/) 
- [Twitter/X](https://x.com/minhajansari_) 
- reproducerai@gmail.com

### Journey

<a href="docs/transformers_vs_mlps.html" target="_blank">
  A Simple Example: Why Transformers Beat MLPs on Long Sequences
</a>
